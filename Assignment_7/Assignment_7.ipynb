{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-5sDeKXuedey"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import (\n",
        "    word_tokenize,\n",
        "    sent_tokenize,\n",
        "    WhitespaceTokenizer,\n",
        "    WordPunctTokenizer\n",
        ")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Resource Setup\n",
        "def setup_resources():\n",
        "    resources = ['punkt', 'punkt_tab', 'averaged_perceptron_tagger_eng', 'wordnet', 'stopwords']\n",
        "    for res in resources:\n",
        "        nltk.download(res, quiet=True)\n",
        "\n",
        "setup_resources()"
      ],
      "metadata": {
        "id": "NsfHX78Xeit4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NLPAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"Removes special characters and extra whitespace.\"\"\"\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "        return text.strip().lower()\n",
        "\n",
        "    def perform_analysis(self, raw_text):\n",
        "        print(f\"Original Text: {raw_text}\\n\")\n",
        "\n",
        "        # A. Sentence Tokenization\n",
        "        sentences = sent_tokenize(raw_text)\n",
        "        print(f\"1. Sentences Detected ({len(sentences)}): {sentences}\")\n",
        "\n",
        "        # B. Word Tokenization (Using WordPunct for detail)\n",
        "        tokens = WordPunctTokenizer().tokenize(raw_text)\n",
        "        print(f\"2. Word Tokens: {tokens[:10]}...\")\n",
        "\n",
        "        # C. Cleaning & Stopword Removal\n",
        "        cleaned = [w.lower() for w in tokens if w.lower().isalnum() and w.lower() not in self.stop_words]\n",
        "        print(f\"3. Cleaned Tokens (No Stopwords): {cleaned[:10]}...\")\n",
        "\n",
        "        # D. POS Tagging\n",
        "        # Tags words as NNP (Proper Noun), VBZ (Verb), JJ (Adjective), etc.\n",
        "        pos_tags = nltk.pos_tag(tokens)\n",
        "        print(\"\\n4. Part-of-Speech (POS) Tagging (First 5):\")\n",
        "        for word, tag in pos_tags[:5]:\n",
        "            print(f\"   {word:<12} -> {tag}\")\n",
        "\n",
        "        # E. Basic Frequency Distribution\n",
        "        freq_dist = nltk.FreqDist(cleaned)\n",
        "        print(f\"\\n5. Most Common Words: {freq_dist.most_common(3)}\")"
      ],
      "metadata": {
        "id": "-Bqy0k77eio4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    analyzer = NLPAnalyzer()\n",
        "\n",
        "    sample_data = (\n",
        "        \"NLTK is a leading platform for building Python programs. \"\n",
        "        \"It provides easy-to-use interfaces to over 50 corpora and lexical resources.\"\n",
        "    )\n",
        "\n",
        "    analyzer.perform_analysis(sample_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1N6h-SQeimB",
        "outputId": "d8ca6172-48b3-4d64-8083-5b975e6ea2d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: NLTK is a leading platform for building Python programs. It provides easy-to-use interfaces to over 50 corpora and lexical resources.\n",
            "\n",
            "1. Sentences Detected (2): ['NLTK is a leading platform for building Python programs.', 'It provides easy-to-use interfaces to over 50 corpora and lexical resources.']\n",
            "2. Word Tokens: ['NLTK', 'is', 'a', 'leading', 'platform', 'for', 'building', 'Python', 'programs', '.']...\n",
            "3. Cleaned Tokens (No Stopwords): ['nltk', 'leading', 'platform', 'building', 'python', 'programs', 'provides', 'easy', 'use', 'interfaces']...\n",
            "\n",
            "4. Part-of-Speech (POS) Tagging (First 5):\n",
            "   NLTK         -> NNP\n",
            "   is           -> VBZ\n",
            "   a            -> DT\n",
            "   leading      -> VBG\n",
            "   platform     -> NN\n",
            "\n",
            "5. Most Common Words: [('nltk', 1), ('leading', 1), ('platform', 1)]\n"
          ]
        }
      ]
    }
  ]
}